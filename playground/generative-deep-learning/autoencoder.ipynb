{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras import layers, Model\n",
    "import keras.backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "IMG_SIZE = 32\n",
    "GRAYSCALE = 255\n",
    "image_input_size = (IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "# images are in 28x28 ints between 0-255 (grayscale)\n",
    "# we want them scaled between 0-1 and padded to 32x32 (28+4)\n",
    "\n",
    "def preprocess_images(images):\n",
    "    return np.pad(images.astype(\"float32\") / GRAYSCALE, ((0, 0), (2, 2), (2, 2)), constant_values=0.0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "x_train = preprocess_images(x_train)\n",
    "x_test = preprocess_images(x_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "(32, 32)"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "encoder_input = layers.Input(shape=image_input_size, name=\"encoder_input\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "(4, 4, 128)"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = layers.Conv2D(IMG_SIZE, (3, 3), strides=2, activation='relu', padding='same')(encoder_input)\n",
    "x = layers.Conv2D(IMG_SIZE * 2, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
    "x = layers.Conv2D(IMG_SIZE * 4, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
    "shape_before_flattening = K.int_shape(x)[1:]\n",
    "shape_before_flattening"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "x = layers.Flatten()(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "encoder_output = layers.Dense(2, name=\"encoder_output\")(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_input (InputLayer)  [(None, 32, 32, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 16, 16, 32)        320       \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 8, 8, 64)          18496     \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " encoder_output (Dense)      (None, 2)                 4098      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 96,770\n",
      "Trainable params: 96,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = Model(encoder_input, encoder_output, name=\"encoder\")\n",
    "encoder.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "decoder_input = layers.Input(shape=(2,), name=\"decoder_input\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "x = layers.Dense(np.prod(shape_before_flattening))(decoder_input)\n",
    "x = layers.Reshape(shape_before_flattening)(x)\n",
    "x = layers.Conv2DTranspose(IMG_SIZE * 4, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
    "x = layers.Conv2DTranspose(IMG_SIZE * 2, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
    "x = layers.Conv2DTranspose(IMG_SIZE, (3, 3), strides=2, activation='relu', padding='same')(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "decoder_output = layers.Conv2D(1, (3, 3), strides=1, activation='sigmoid', padding='same', name=\"decoder_output\")(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " decoder_input (InputLayer)  [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2048)              6144      \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_6 (Conv2DT  (None, 8, 8, 128)        147584    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_7 (Conv2DT  (None, 16, 16, 64)       73792     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_8 (Conv2DT  (None, 32, 32, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " decoder_output (Conv2D)     (None, 32, 32, 1)         289       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 246,273\n",
      "Trainable params: 246,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder = Model(decoder_input, decoder_output, name=\"decoder\")\n",
    "decoder.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_input (InputLayer)  [(None, 32, 32, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 16, 16, 32)        320       \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 8, 8, 64)          18496     \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " encoder_output (Dense)      (None, 2)                 4098      \n",
      "                                                                 \n",
      " decoder (Functional)        (None, 32, 32, 1)         246273    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 343,043\n",
      "Trainable params: 343,043\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Model(encoder_input, decoder(encoder_output), name=\"autoencoder\")\n",
    "autoencoder.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "600/600 [==============================] - 5s 8ms/step - loss: 0.3029 - val_loss: 0.2662\n",
      "Epoch 2/3\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.2620 - val_loss: 0.2592\n",
      "Epoch 3/3\n",
      "600/600 [==============================] - 4s 7ms/step - loss: 0.2560 - val_loss: 0.2556\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7f08c52d4e20>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(\n",
    "    x_train,\n",
    "    x_train,\n",
    "    epochs=3,\n",
    "    batch_size=100,\n",
    "    shuffle=True,\n",
    "    validation_data=(x_test, x_test)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
